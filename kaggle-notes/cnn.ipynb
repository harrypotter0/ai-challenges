{"cells":[{"metadata":{"collapsed":true,"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0"},"cell_type":"markdown","source":"# Convolutional Neural Networks for Sign Languag\nIf you are not familiar with nueral network, I suggest you to read this tutorial:\n\nhttps://www.kaggle.com/kanncaa1/deep-learning-tutorial-for-beginners"},{"metadata":{"_uuid":"d78a1591275152d0b8b9733d32a898a7333cec55","_cell_guid":"1bbe722e-9d1c-47e6-a660-3e8af93c0c9c"},"cell_type":"markdown","source":"## Introduction:\n\n### Basic reminder:\n\n** What is Neural Network**\n\nThe simplest definition of a neural network, more properly referred to as an 'artificial' neural network (ANN), is provided by the inventor of one of the first neurocomputers, Dr. Robert Hecht-Nielsen. He defines a neural network as:\n\n\"...a computing system made up of a number of simple, highly interconnected processing elements, which process information by their dynamic state response to external inputs.\"\n\n** The Basics of Neural Networks** \n\nNeural neworks, shown in Fig1, are typically organized in layers. Layers are made up of a number of interconnected 'nodes' which contain an 'activation function'. Patterns are presented to the network via the 'input layer', which communicates to one or more 'hidden layers' where the actual processing is done via a system of weighted 'connections'. The hidden layers then link to an 'output layer' where the Most ANNs contain some form of 'learning rule' which modifies the weights of the connections according to the input patterns that it is presented with. In a sense, ANNs learn by example as do their biological counterparts; a child learns to recognize dogs from examples of dogs [1]."},{"metadata":{"_uuid":"4068a0888b2a1ed593ec340adb63f8ec3a9b8eb2","_cell_guid":"0a2caff6-21b0-4b43-a6ef-1797d487aaf6"},"cell_type":"markdown","source":"Fig.1: https://medium.com/@curiousily/tensorflow-for-hackers-part-iv-neural-network-from-scratch-1a4f504dfa8"},{"metadata":{"_uuid":"7ebb0efc02b20e250d1f9e878e58ab59d7843256","_cell_guid":"dcb5271b-4d62-41e1-8540-378b75b40eda"},"cell_type":"markdown","source":"\n<a href=\"http://imgbb.com/\"><img src=\"http://image.ibb.co/dhpBmc/1_QVIyc5_Hn_GDWTNX3m_n_Im9w.png\" alt=\"1 QVIyc5 Hn GDWTNX3m n Im9w\" border=\"0\" /></a>\n"},{"metadata":{"_uuid":"eee0d8c45d011b1537140ffb43d514adca8e6590","_cell_guid":"e837d315-fd89-4f25-84ed-38a16a67194e"},"cell_type":"markdown","source":"A neural network is basically a sequence of operations applied to a matrix of input data. These operations are usually collections of additions and multiplications followed by applications of non-linear functions. The important trick with neural networks is called backpropagation. Back propagation is a procedure that allows us to update the model variables based on the learning rate and the output of the loss function.\n\nBackpropagation, short for \"backward propagation of errors,\" is an algorithm for supervised learning of artificial neural networks using gradient descent. Given an artificial neural network and an error function, the method calculates the gradient of the error function with respect to the neural network's weights. It is a generalization of the delta rule for perceptrons to multilayer feedforward neural networks. The \"backwards\" part of the name stems from the fact that calculation of the gradient proceeds backwards through the network, with the gradient of the final layer of weights being calculated first and the gradient of the first layer of weights being calculated last. Partial computations of the gradient from one layer are reused in the computation of the gradient for the previous layer. This backwards flow of the error information allows for efficient computation of the gradient at each layer versus the naive approach of calculating the gradient of each layer separately [2].\n\nAnother important feature to take note of in neural networks is the non-linear activation function. Since most neural networks are just combinations of addition and multiplication operations, they will not be able to model non-linear datasets. To address this issue, we have used the non-linear activation functions in the neural networks. This will allow the neural network to adapt to most non-linear situations.\nFig2:"},{"metadata":{"_uuid":"176248819188053c423732355b10d5412c374c72","_cell_guid":"5707dbd3-9e9b-4a44-992a-92956f5b4d51"},"cell_type":"markdown","source":"<img src=\"https://image.ibb.co/cw5Fex/img10.png\" alt=\"img10\" border=\"0\" />"},{"metadata":{"_uuid":"a703d0bd761762524489093bb2c6df331defb72b","_cell_guid":"e380b1d6-a57f-4226-99d0-48ec14564b2a"},"cell_type":"markdown","source":"different types of activation:"},{"metadata":{"_uuid":"0abbeb0ed700fd5f4b2b198eb50020c9c9cb9792","_cell_guid":"afb5a026-2939-420e-b89b-7f35ea8b7c99"},"cell_type":"markdown","source":"<img src=\"https://image.ibb.co/mCQOzx/activation_functions.png\" alt=\"activation functions\" border=\"0\" />"},{"metadata":{"_uuid":"551ac6d9204833f99df5312b4122200b2d7c8ce2","_cell_guid":"5b9abac3-baa5-4ea8-8001-c41517e88a94"},"cell_type":"markdown","source":"** Optimization Algorithm **\n\nThe **Adam optimization** algorithm is an extension to stochastic gradient descent. Adam is an optimization algorithm that can used instead of the classical stochastic gradient descent procedure to update network weights iterative based in training data. Adam was presented by Diederik Kingma from OpenAI and Jimmy Ba from the University of Toronto in their 2015 ICLR paper (poster) titled “Adam: A Method for Stochastic Optimization“. \n\n- How Does Adam Work?\n\nAdam is different to classical stochastic gradient descent.Stochastic gradient descent maintains a single learning rate (termed alpha) for all weight updates and the learning rate does not change during training.\n\n\nThe authors describe Adam as combining the advantages of two other extensions of stochastic gradient descent. Specifically:\n\n- **Adaptive Gradient Algorithm (AdaGrad)** that maintains a per-parameter learning rate that improves performance on problems with sparse gradients (e.g. natural language and computer vision problems).\n\n- **Root Mean Square Propagation (RMSProp)** that also maintains per-parameter learning rates that are adapted based on the average of recent magnitudes of the gradients for the weight (e.g. how quickly it is changing). This means the algorithm does well on online and non-stationary problems (e.g. noisy).\nAdam realizes the benefits of both AdaGrad and RMSProp.\n\nInstead of adapting the parameter learning rates based on the average first moment (the mean) as in RMSProp, Adam also makes use of the average of the second moments of the gradients (the uncentered variance).\n\nSpecifically, the algorithm calculates an exponential moving average of the gradient and the squared gradient, and the parameters beta1 and beta2 control the decay rates of these moving averages.\n\nThe initial value of the moving averages and beta1 and beta2 values close to 1.0 (recommended) result in a bias of moment estimates towards zero. This bias is overcome by first calculating the biased estimates before then calculating bias-corrected estimates [3]. More details [4,5].\n"},{"metadata":{"_uuid":"ff19101eebe6e3b42ca84ed1f070980c1b5c128b","_cell_guid":"94a06c4b-0597-4887-91f2-c3b12536ba74"},"cell_type":"markdown","source":"## Convolutional Neural Networks\n\n** What does Convolution mean? **\n\nIn mathematics, a convolution is a function which is applied over the output of another function. In our case, we will consider applying a matrix multiplication (filter/Kernel) across an image [6]. In deep learning, cross-correlation is called convolution although convultion operation in math the is a little different from cross-correlation [7]. "},{"metadata":{"_uuid":"8cc5ba208dfdfed24b50df718189d4147afafdc9","_cell_guid":"ae1b6bb9-14fd-4df5-829f-ce024bc27832"},"cell_type":"markdown","source":"Fig.4: https://stats.stackexchange.com/questions/114385/what-is-the-difference-between-convolutional-neural-networks-restricted-boltzma"},{"metadata":{"_uuid":"d8f5ea75499e357aa28410f3cd29b509c57dfcff","_cell_guid":"645c5f7b-dccb-402f-9bc9-120df6083be1"},"cell_type":"markdown","source":"<img src=\"https://image.ibb.co/nxGfex/GvsBA.jpg\" alt=\"GvsBA\" border=\"0\" />"},{"metadata":{"_uuid":"66e1620a818d4d5dd3b462c313a1e359c29183f3","_cell_guid":"6e54521f-f0c9-4f0c-8153-4a3d5af04d2b"},"cell_type":"markdown","source":"** Convolutional Neural Networks **\n\nConvolutional Neural Networks (CNNs) are are a special kind of multi-layer neural networks. They are made up of neurons that have learnable weights and biases. Each neuron receives some inputs, performs a dot product and optionally follows it with a non-linearity. The whole network still expresses a single differentiable score function: from the raw image pixels on one end to class scores at the other. And they still have a loss function (e.g. SVM/Softmax) on the last (fully-connected) layer. However, ConvNet architectures make the explicit assumption that the inputs are images, which allows us to encode certain properties into the architecture. These then make the forward function more efficient to implement and vastly reduce the amount of parameters in the network [8]. Therefore, they can recognize patterns with extreme variability (such as handwritten characters), and with robustness to distortions and simple geometric transformations [9]. CNNs have various architectures: LeNet, AlexNet, VGG, GoogLeNet, ResNet and etc. Here, LENET-5 one of the simplest architectures is considered to make a prediction the sign languge. \n\nBefore studying LeNet, we need to learn another concept which is called pooling.  "},{"metadata":{"_uuid":"0b812a72926cbb5a35c02d169d89710d02b774dd","_cell_guid":"81af4f39-0d4c-411e-87db-54215c28e420"},"cell_type":"markdown","source":"** Stride and Padding **\n\nStride controls how the filter convolves around the input volume. The filter convolves around the input volume by shifting one/two, .. unit at a time.  Stride is normally set in a way so that the output volume is an integer and not a fraction. Let’s look at an example. Let’s imagine a 7 x 7 input volume, a 3 x 3 filter (Disregard the 3rd dimension for simplicity), and a stride of 2. So, as you can see, the receptive field is shifting by 2 units now and the output volume shrinks as well. Notice that if we tried to set our stride to 3, then we’d have issues with spacing and making sure the receptive fields fit on the input volume. Normally, programmers will increase the stride if they want receptive fields to overlap less and if they want smaller spatial dimensions."},{"metadata":{"_uuid":"ee9e9afab23536d5b1fc9e859f483a0ded5409a5","_cell_guid":"6d4652d5-096b-4e70-afe9-34c041c09a2e"},"cell_type":"markdown","source":"Fig 5: https://adeshpande3.github.io/A-Beginner%27s-Guide-To-Understanding-Convolutional-Neural-Networks-Part-2/"},{"metadata":{"_uuid":"08bf086f01e524225650539769deef76bf0c6c30","_cell_guid":"d36068d9-9002-43da-ba7d-27d94535fce3"},"cell_type":"markdown","source":"<img src=\"https://image.ibb.co/hAK0ex/Stride2.png\" alt=\"Stride2\" border=\"0\" />"},{"metadata":{"_uuid":"3b530aaffd9ad034567bb208ae885f942f9ed51f","_cell_guid":"f35d2c94-be5f-45da-b1fe-01de0107d529"},"cell_type":"markdown","source":"** Padding **\n\nWhat happens when you apply three 5 x 5 x 3 filters to a 32 x 32 x 3 input volume? The output volume would be 28 x 28 x 3. Notice that the spatial dimensions decrease. As we keep applying conv layers, the size of the volume will decrease faster than we would like. In the early layers of our network, we want to preserve as much information about the original input volume so that we can extract those low level features. Let’s say we want to apply the same conv layer but we want the output volume to remain 32 x 32 x 3. To do this, we can apply a zero padding of size 2 to that layer. Zero padding pads the input volume with zeros around the border. If we think about a zero padding of two, then this would result in a 36 x 36 x 3 input volume."},{"metadata":{"_uuid":"480acdfa0cd302d5d1306130fd60f88b6503b9a4","_cell_guid":"73525516-65b9-4367-a038-57009adde3d1"},"cell_type":"markdown","source":"Fig 6:\n<img src=\"https://image.ibb.co/cfXQCH/Pad.png\" alt=\"Pad\" border=\"0\" />"},{"metadata":{"_uuid":"20ce0b79387fb49e6190aa3a8a51f01797ca535f","_cell_guid":"ce67d72f-ea4f-4bf0-a33a-a01f9de90a33"},"cell_type":"markdown","source":"** Pooling? **\n\nIt is also referred to as a downsampling layer. In this category, there are also several layer options, with maxpooling being the most popular. This basically takes a filter (normally of size 2x2) and a stride of the same length. It then applies it to the input volume and outputs the maximum number in every subregion that the filter convolves around."},{"metadata":{"_uuid":"1446a855137ef682ec8f9024fb13e3bb43a14004","_cell_guid":"977a01a1-2900-46d9-b54f-6730c105d235"},"cell_type":"markdown","source":"<img src=\"https://image.ibb.co/b79izx/Max_pooling.png\" alt=\"Max pooling\" border=\"0\" />"},{"metadata":{"_uuid":"db8f27c8ec4ad5f520847273f0526bce694f8459","_cell_guid":"5f16ec74-a9c7-4877-adf3-95ec1c791879"},"cell_type":"markdown","source":"** Input and Output size**\n\nThe formula for calculating the output size for any given conv layer is\n\ninput----------filter-------------------output\n\nn $\\times$ n----*----f $\\times$ f --------$[\\frac{n+2p-f}{s} + 1] \\times [\\frac{n+2p-f}{s} + 1]$ \n\nwhere n is input size for example $32 \\times 32 \\times 1$, $p$ is padding, $f$ number of filters and $s$ is stride\n"},{"metadata":{"_uuid":"0fbdd09d1608fd2658fa98aec792b7f5939afc12","_cell_guid":"7811bd66-46bb-4cfd-9f55-c99d47caae67"},"cell_type":"markdown","source":"**LeNet-5 (1998)**:\n\nLeNet-5, a pioneering 7-level convolutional network by LeCun et al in 1998, that classifies digits, was applied by several banks to recognise hand-written numbers on checks (cheques) digitized in 32x32 pixel images. The ability to process higher resolution images requires larger and more convolutional layers, so this technique is constrained by the availability of computing resources [10]. For example, leNet-5 Start with an image of 32 x 32 x 1 and goal was to recognize handwritten digit. In the first step we use six 5 x 5 filter with stride 1 and get 28 x 28 x 6. With stride of 1 and no padding we reduce the dimension to 32 x 32 to 28 x 28. Then we use a average pooling with a filter width of 2 and stride of 2 and reduce the dimension by factor of 2 and end up with 14 x 14 x 6. Then we use another convolutional layer with sixteen 5 x 5 filter and end up with 10 x 10 x 16. That time people use valid padding that’s why each time height and weight shrinks. Then another pooling layer and end up with 5 x 5 x 16. Then the next layer is a fully connected layer with 120 nodes. The previous layers 400 (5*5*16) then connected with this 120 neurons. Then another layer this 120 nodes connected with a 84 node and use this to connected with Yhat with possible 10 values that will recognize digit from 0 to 9. But in modern version of this neural net we use softmax function with a ten wave classification output [11]."},{"metadata":{"_uuid":"120af6d9147636d15b8d63ad3066200269cf5f6b","_cell_guid":"33aac3cc-c4d3-4204-a201-2a168053fa31"},"cell_type":"markdown","source":"<img src=\"https://image.ibb.co/hydtzx/1_l_0_Pe_Sh3o_L2_Wc2ri2s_VWA.png\" alt=\"1 l 0 Pe Sh3o L2 Wc2ri2s VWA\" border=\"0\" />"},{"metadata":{"_uuid":"174df4175b98a0081110eb37b4436d9015f90e88","_cell_guid":"b6684e73-1f87-401e-8ea9-3d11c6fc34b5"},"cell_type":"markdown","source":"## Overview the Data Set:\n\n- Image size: 64x64\n- Color space: Grayscale\n- File format: npy\n- Number of classes: 10 (Digits: 0-9)\n- Number of participant students: 218\n- Number of samples per student: 10"},{"metadata":{"_uuid":"66677f73897692b0941135e85bba46591f173367","_cell_guid":"c4c7155e-a464-43ee-b356-10956e2c7479","trusted":true},"cell_type":"code","source":"import tensorflow as tf","execution_count":1,"outputs":[]},{"metadata":{"collapsed":true,"_uuid":"ce0669d7e7601d1c0b448dade5f3dfec93738276","_cell_guid":"67d48ad4-72e4-4f83-bc32-144c37241c1f","trusted":true},"cell_type":"code","source":"import numpy as np\nimport pandas as pd\n\nimport warnings\nwarnings.filterwarnings('ignore')\nfrom subprocess import check_output\n\n%matplotlib inline\nimport matplotlib.pyplot as plt\nimport tensorflow as tf\n# import numpy as np\nfrom sklearn.metrics import confusion_matrix\nimport time\nfrom datetime import timedelta\nimport math\n\nfrom sklearn.model_selection import train_test_split","execution_count":2,"outputs":[]},{"metadata":{"collapsed":true,"_uuid":"f73057797f67d7199a1ca7321e32fdaa17f5c21d","_cell_guid":"bd57207e-4ccc-40d5-a1f5-2e04fcb22911","trusted":true},"cell_type":"code","source":"import glob\nimport os\nimport math\nimport operator\nimport functools\nimport random\nimport datetime\nfrom scipy.ndimage.interpolation import rotate, shift, zoom","execution_count":3,"outputs":[]},{"metadata":{"collapsed":true,"_uuid":"93df12f4c1775d617badb2ac2a861aecbc6cde85","_cell_guid":"e4dc95fd-e616-4111-994a-50f5dd518b06","trusted":true},"cell_type":"code","source":"# load data set\nall_X = np.load('../input/Sign-language-digits-dataset/X.npy')\nall_Y = np.load('../input/Sign-language-digits-dataset/Y.npy')","execution_count":4,"outputs":[]},{"metadata":{"collapsed":true,"_uuid":"8ed4d74148aa747ee8f86e5f82477f57ecb3db6a","_cell_guid":"723462a8-7660-4f6d-a4a0-c479afd6fa7b","trusted":true},"cell_type":"code","source":"# Train Test split\ntest_size = 0.15\nX_train, X_test, Y_train, Y_test = train_test_split(all_X, all_Y, test_size=test_size, random_state=42)","execution_count":5,"outputs":[]},{"metadata":{"_uuid":"5391176c39fa0f7f408ca991daa0869045ab3bf8","_cell_guid":"13b67084-b56f-4fcc-b0af-8bafb7a9a239","trusted":true},"cell_type":"code","source":"print('Training shape:', X_train.shape)\nprint(X_train.shape[0], 'sample,',X_train.shape[1] ,'x',X_train.shape[2] ,'size grayscale image.\\n')\nprint('Test shape:', X_test.shape)\nprint(X_test.shape[0], 'sample,',X_test.shape[1] ,'x',X_test.shape[2] ,'size grayscale image.\\n')","execution_count":6,"outputs":[]},{"metadata":{"collapsed":true,"_uuid":"726ae713268a7f9196de3014cb0714a0c29cb56c","_cell_guid":"2656f55f-6d13-4bae-b2ce-006e674a541b","trusted":true},"cell_type":"code","source":"# Train and test classification between 0-10\nY_test_cls = np.argmax(Y_test, axis=1)\nY_train_cls = np.argmax(Y_train, axis=1)","execution_count":7,"outputs":[]},{"metadata":{"_uuid":"15d694328ff36434f2771861875f365a81cc2d89","_cell_guid":"648be2c0-e28d-4687-a9e9-f96f2b105f84"},"cell_type":"markdown","source":"## Data Dimensions\nThe data dimensions are used in several places in the source-code below. They are defined once so we can use these variables instead of numbers throughout the source-code below"},{"metadata":{"collapsed":true,"_uuid":"be160ed97dbffec147173c2e52183591e63c87d3","_cell_guid":"016d2d4e-bcba-4b62-aa1c-a17f357ce17c","trusted":true},"cell_type":"code","source":"# We know that MNIST images are 28 pixels in each dimension.\nimg_size = 64\n\n# Images are stored in one-dimensional arrays of this length.\nimg_size_flat = img_size * img_size\n\n# Tuple with height and width of images used to reshape arrays.\nimg_shape = (img_size, img_size)\n\n# Number of colour channels for the images: 1 channel for gray-scale.\nnum_channels = 1\n\n# Number of classes, one class for each of 10 digits.\nnum_classes = 10","execution_count":8,"outputs":[]},{"metadata":{"collapsed":true,"_uuid":"a37e132997c5a3dbf867b9984f09c98430eb3ade","_cell_guid":"b4e967a0-b4ed-49f5-8ac0-c37d2a8640be"},"cell_type":"markdown","source":"## Plot Images\nFunction used to plot 9 images in a 3x3 grid, and writing the true and predicted classes below each image."},{"metadata":{"collapsed":true,"_uuid":"8bcb907988983ecc3601fbd3d5983468dd0c28b2","_cell_guid":"7d4e586a-d929-407e-9f3a-bc215b1fa99c","trusted":true},"cell_type":"code","source":"def plot_images(images, cls_true, cls_pred=None):\n    assert len(images) == len(cls_true) == 9\n    \n    # Create figure with 3x3 sub-plots.\n    fig, axes = plt.subplots(3, 3)\n    fig.subplots_adjust(hspace=0.3, wspace=0.3)\n\n    for i, ax in enumerate(axes.flat):\n        # Plot image.\n        ax.imshow(images[i].reshape(img_shape), cmap='binary')\n\n        # Show true and predicted classes.\n        if cls_pred is None:\n            xlabel = \"True: {0}\".format(cls_true[i])\n        else:\n            xlabel = \"True: {0}, Pred: {1}\".format(cls_true[i], cls_pred[i])\n\n        # Show the classes as the label on the x-axis.\n        ax.set_xlabel(xlabel)\n        \n        # Remove ticks from the plot.\n        ax.set_xticks([])\n        ax.set_yticks([])\n    \n    plt.show()","execution_count":9,"outputs":[]},{"metadata":{"_uuid":"4f96ac0cb7dd341bc52070e79ec096d0531bce73","_cell_guid":"970acd50-b8bf-4fed-90a8-7815f5ac235e"},"cell_type":"markdown","source":"** Plot a few images to see if data is correct **"},{"metadata":{"_uuid":"3a0aab1b241d145c9d9cc8db84a5bf96d3491e1e","_cell_guid":"70f6cc88-7ae7-4959-a0b7-5e86d455fcd2","trusted":true},"cell_type":"code","source":"# Get the first images from the test-set.\nimages = X_test[0:9]\n\n# Get the true classes for those images.\ncls_true = Y_test_cls[0:9]\n\n# Plot the images and labels using our helper-function above.\nplot_images(images=images, cls_true=cls_true)","execution_count":10,"outputs":[]},{"metadata":{"_uuid":"721cdb7e65880031d6c3762f4436dd578dd741c9","_cell_guid":"eaa0a941-3f2c-4989-884d-2c7aeebcb8a5"},"cell_type":"markdown","source":"## Data prepration"},{"metadata":{"collapsed":true,"_uuid":"75c7709d606ea22fb4124228bb294d1824921b7b","_cell_guid":"65bc2ec1-2ce4-4c16-a716-a3a2c017b335","trusted":true},"cell_type":"code","source":"train_X = X_train\ntrain_Y = Y_train\nnew_train_X = train_X.reshape(X_train.shape[0],img_size_flat)\nnew_test_X = X_test.reshape(X_test.shape[0],img_size_flat)","execution_count":11,"outputs":[]},{"metadata":{"_uuid":"1b980e08f2ce5ceb97a4f12f53a648a5cd7fac10","_cell_guid":"e6818dd8-a86a-4391-96e8-cf9d2825303c","trusted":true},"cell_type":"code","source":"# Shapes of training set\nprint(\"Training set (images) shape: {shape}\".format(shape=new_train_X.shape))\nprint(\"Training set (labels) shape: {shape}\".format(shape=train_Y .shape))\n\n# Shapes of test set\nprint(\"Test set (images) shape: {shape}\".format(shape=new_test_X.shape))\nprint(\"Test set (labels) shape: {shape}\".format(shape=Y_test.shape))\n","execution_count":12,"outputs":[]},{"metadata":{"_uuid":"e6b6c7c3d0bc4746de1e64fde3588fabcea141db","_cell_guid":"895e4520-ba37-47a9-9ce8-515823b66db5"},"cell_type":"markdown","source":"## Configuration of Neural Network\nThe configuration of the Convolutional Neural Network is defined here for convenience, so you can easily find and change these numbers and re-run the Notebook."},{"metadata":{"collapsed":true,"_uuid":"e1cca98ab871b017d9204999c60fd1ebfd6f22f2","_cell_guid":"19ff007d-c8f7-4375-816f-02d161f504b2","trusted":true},"cell_type":"code","source":"# architecture hyper-parameter\nlearning_rate = 0.001\ntraining_iters = 40000\nbatch_size = 16\ndisplay_step = 20\n\nn_input = img_size_flat # 64x64 image\ndropout = 0.75 ","execution_count":13,"outputs":[]},{"metadata":{"_uuid":"bbbcee4a121478fe7c5cedcd105332ae3d781cb8","_cell_guid":"9c9df102-d45a-4ff1-b5a8-2e2893339396"},"cell_type":"markdown","source":"## TensorFlow Graph\n\nThe entire purpose of TensorFlow is to have a so-called computational graph that can be executed much more efficiently than if the same calculations were to be performed directly in Python. TensorFlow can be more efficient than NumPy because TensorFlow knows the entire computation graph that must be executed, while NumPy only knows the computation of a single mathematical operation at a time.\n\nTensorFlow can also automatically calculate the gradients that are needed to optimize the variables of the graph so as to make the model perform better. This is because the graph is a combination of simple mathematical expressions so the gradient of the entire graph can be calculated using the chain-rule for derivatives.\n\nA TensorFlow graph consists of the following parts which will be detailed below:\n- Placeholder variables used for inputting data to the graph.\n- Variables that are going to be optimized so as to make the convolutional network perform better.\n- The mathematical formulas for the convolutional network.\n- A cost measure that can be used to guide the optimization of the variables.\n- An optimization method which updates the variable"},{"metadata":{"_uuid":"477c31f9d48ef9f1bf90fcd1c15312ae4fa06326","_cell_guid":"e84d7361-02ed-4f74-989e-2328d1fe4f4f"},"cell_type":"markdown","source":"## Placeholder variables\nPlaceholder variables serve as the input to the TensorFlow computational graph that we may change each time we execute the graph. We call this feeding the placeholder variables and it is demonstrated further below.\nFirst we define the placeholder variable for the input images. This allows us to change the images that are input to the TensorFlow graph. This is a so-called tensor, which just means that it is a multi-dimensional vector or matrix. "},{"metadata":{"_uuid":"4fe1bb036c59928fa6b1b7207064d8d5c8bfc590","_cell_guid":"f684719a-18ea-4ef4-a67b-eff38bb630fd"},"cell_type":"markdown","source":"## Making Model:"},{"metadata":{"_uuid":"f8efafe41d5d078fe0e58122ae2de0fc7f0b65e3","_cell_guid":"34f2c362-9e89-4345-810c-9c5fcb25663d","trusted":true},"cell_type":"code","source":"x = tf.placeholder(tf.float32, [None, n_input])\ny = tf.placeholder(tf.float32, [None, num_classes])\nkeep_prob = tf.placeholder(tf.float32)\nprint('Shape of placeholder',x.shape, y.shape)","execution_count":14,"outputs":[]},{"metadata":{"_uuid":"7cb6b9b41f80e32ec6ad726fa2bd87fd99d7bd48","_cell_guid":"f55a0b39-74ce-428d-a6c0-124840001430"},"cell_type":"markdown","source":"** convolution for 2 dimensions **:"},{"metadata":{"_uuid":"5a0946162b1852c879d68ca7142284d7fb34d831","_cell_guid":"4fdb414b-e775-40bd-9cfd-18d26d4588ca"},"cell_type":"markdown","source":"**SAME padding**\n\n\nsometimes called **HALF padding**. It is called SAME because for a convolution with a stride=1, (or for pooling) it should produce output of the same size as the input. It is\n\n$p = [k/2]$\n\ncalled HALF because for a kernel of size k [12]. \"SAME\" tries to pad evenly left and right, but if the amount of columns to be added is odd, it will add the extra column to the right, as is the case in this example (the same logic applies vertically: there may be an extra row of zeros at the bottom)."},{"metadata":{"collapsed":true,"_uuid":"6e2711ca788070fa6865c1a3c02c2ac4a5afa4fe","_cell_guid":"a590e882-d569-4fef-982d-71b0ab4dd49d","trusted":true},"cell_type":"code","source":"def conv2d(x, W, b, strides=1):\n    x = tf.nn.conv2d(x, W, strides=[1, strides, strides, 1], padding='SAME')\n    x = tf.nn.bias_add(x, b)\n    return tf.nn.relu(x)","execution_count":15,"outputs":[]},{"metadata":{"_uuid":"d6d4a61773b640acea381164afb7121f5c413f17","_cell_guid":"8c3b8a53-2cda-4d37-aff3-1fe91a951ae1"},"cell_type":"markdown","source":"** MaxPool **"},{"metadata":{"collapsed":true,"_uuid":"a08ac92a6124a4d5d7d312270fbfa9381591695f","_cell_guid":"49533322-12b2-4ebe-8700-c64f8fdd93b6","trusted":true},"cell_type":"code","source":"def maxpool2d(x, k=2):\n    return tf.nn.max_pool(x, ksize=[1, k, k, 1], strides=[1, k, k, 1], padding='SAME')","execution_count":16,"outputs":[]},{"metadata":{"collapsed":true,"_uuid":"58e8eeff4150938dc1c4b3db7aee887558cfd289","_cell_guid":"44154ef9-db00-4a29-880e-71d2047da2eb","trusted":true},"cell_type":"code","source":"def conv_net(x, weights, biases, dropout):\n    # reshape input to 64x64 size\n    x = tf.reshape(x, shape=[-1, 64, 64, 1])\n    \n\n    # Convolution layer 1\n    conv1 = conv2d(x, weights['wc1'], biases['bc1'])\n    # Max pooling\n    conv1 = maxpool2d(conv1, k=2)\n\n    # Convolution layer 2\n    conv2 = conv2d(conv1, weights['wc2'], biases['bc2'])\n    # Max pooling\n    conv2 = maxpool2d(conv2, k=2)\n\n    # Fully connected layer\n    fc1 = tf.reshape(conv2, [-1, weights['wd1'].get_shape().as_list()[0]])\n    fc1 = tf.add(tf.matmul(fc1, weights['wd1']), biases['bd1'])\n    fc1 = tf.nn.relu(fc1) # layer\n    fc1 = tf.nn.dropout(fc1, dropout)\n\n    out = tf.add(tf.matmul(fc1, weights['out']), biases['out'])\n    return out","execution_count":17,"outputs":[]},{"metadata":{"collapsed":true,"_uuid":"5054efefbfb84212cf1fb84d022dd41c6ff2b33c","_cell_guid":"799e850f-e928-4f1c-9c06-7c930f228ba3","trusted":true},"cell_type":"code","source":"weights = {\n    'wc1': tf.Variable(tf.random_normal([5, 5, 1, 32]),name='wc1'),\n    'wc2': tf.Variable(tf.random_normal([5, 5, 32, 64]),name='wc2'),\n    'wd1': tf.Variable(tf.random_normal([64 * 64 * 4, 1024]),name='wd1'),\n    'out': tf.Variable(tf.random_normal([1024, num_classes]),name='wout')\n}\n\nbiases = {\n    'bc1': tf.Variable(tf.random_normal([32]),name='bc1'),\n    'bc2': tf.Variable(tf.random_normal([64]),name='bc2'),\n    'bd1': tf.Variable(tf.random_normal([1024]),name='bd1'),\n    'out': tf.Variable(tf.random_normal([num_classes]),name='bout')\n}","execution_count":18,"outputs":[]},{"metadata":{"_uuid":"cefd203f74d80d95d5364700d5184ab4d151a49f","_cell_guid":"f1ae1f83-1831-4fe2-9444-a78477c952e0"},"cell_type":"markdown","source":"**Optimization Method**\n\nNow that we have a cost measure that must be minimized, we can then create an optimizer. In this case it is the AdamOptimizer which is an advanced form of Gradient Descent.\n\nNote that optimization is not performed at this point. In fact, nothing is calculated at all, we just add the optimizer-object to the TensorFlow graph for later execution.\n\n**Performance Measures **\n\nWe need a few more performance measures to display the progress to the user."},{"metadata":{"_uuid":"20fffd0c63bdff18a46b9320a1af0c4ee2075811","_cell_guid":"12118203-da94-4155-906e-8e78d9aceabb","trusted":true},"cell_type":"code","source":"# Create the model\nmodel = conv_net(x, weights, biases, keep_prob)\nprint(model)\n# Define loss and optimizer\ncost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=model, labels=y))\noptimizer = tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(cost)\n\n# Evaluate model\ny_true_cls =  tf.argmax(y, 1)\ny_pred_cls = tf.argmax(model, 1)\n# This is a vector of booleans whether the predicted \n#class equals the true class of each image.\ncorrect_model = tf.equal(y_pred_cls,y_true_cls)\n# This calculates the classification accuracy by first type-casting \n#the vector of booleans to floats, so that False becomes 0 and True becomes 1,\n#and then calculating the average of these numbers.\naccuracy = tf.reduce_mean(tf.cast(correct_model, tf.float32))\n\n# Initializing the variables\ninit = tf.global_variables_initializer()","execution_count":19,"outputs":[]},{"metadata":{"_uuid":"05bceb38047d5607475fde1c4f6faf34b4d2cd8a","_cell_guid":"2a51ce60-9ffe-4677-904e-05ad76b2a0c6"},"cell_type":"markdown","source":"** Get Batch**\n\nGet Batch: defines number of samples that going to be propagated through the network.\nBatch Size : Total number of training examples present in a single batch.\nWe can’t pass the entire dataset into the neural net at once. So, you divide dataset into Number of Batches or sets or parts."},{"metadata":{"collapsed":true,"_uuid":"375ab54cd7dd5598cef6c0bae8be61ae9f9e6dd6","_cell_guid":"d9fbc34c-4cdd-43e1-b677-68e100d3ca51","trusted":true},"cell_type":"code","source":"def getBatch(X, Y, batchSize=16):\n    \"\"\"\n    Creates a list of random minibatches from (X, Y)\n    \n    Arguments:\n    X -- input train/test \n    Y --input label train/test\n    \n    Returns:\n    mini_batches -- tuple of synchronous (mini_batch_X, mini_batch_Y)\n    \n    \"\"\"\n    arrayLength = X.shape[0]\n    count = 0 \n    \n    while count < arrayLength/batchSize:\n        random.seed(datetime.datetime.now())\n        randstart = random.randint(0, arrayLength-batchSize-1)\n#         print(randstart)\n        count += 1\n        yield (X[randstart:randstart+batchSize], Y[randstart:randstart+batchSize]) \n","execution_count":20,"outputs":[]},{"metadata":{"_uuid":"00558e059d507be36aa6f1f0f3b6cda31d304adb","_cell_guid":"124c5be4-65f5-496f-ba5f-4f8bb1f047df","trusted":true},"cell_type":"code","source":"loss_t = []\nsteps_t = []\nacc_t = []\n\n# Launch the graph\nwith tf.Session() as sess:\n    sess.run(init)\n    step = 1   \n#     Keep training until reach max iterations\n    while step * batch_size < training_iters:\n        a = getBatch(new_train_X,train_Y, batch_size)\n        batch_x, batch_y = next(a)\n        sess.run(optimizer, feed_dict={x: batch_x, y: batch_y, keep_prob: dropout})\n        if step % display_step == 0:\n            print('*'*15)\n            loss, acc = sess.run([cost, accuracy], feed_dict={x: batch_x,\n                                                              y: batch_y,\n                                                              keep_prob: 1.})\n            print(\"Iter \" + str(step*batch_size) + \", Loss= \" + \\\n                  \"{:.3f}\".format(loss) + \", Training Accuracy= \" + \\\n                  \"{:.3f}\".format(acc))\n            loss_t.append(loss)\n            steps_t.append(step*batch_size)\n            acc_t.append(acc)\n        step += 1\n    \n   #\n    print(\"Testing Accuracy:\", \\\n        sess.run(accuracy, feed_dict={x: new_test_X,\n                                      y: Y_test,\n                                      keep_prob: 1.}))\n    \n    cls_pred = sess.run(y_pred_cls, feed_dict={x: new_test_X,\n                                      y: Y_test,\n                                      keep_prob: 1.})\n","execution_count":21,"outputs":[]},{"metadata":{"_uuid":"e2c648ce9e983d3d5ed4c3fd93c5e044d095e68f","_cell_guid":"127da4f5-e266-486b-ab7e-9c97f4e8dfcb","trusted":true},"cell_type":"code","source":"plt.plot(steps_t, loss_t, 'r--')\nplt.xlabel(\"Number of Iterarion\")\nplt.ylabel(\"Loss\")\nplt.show()","execution_count":22,"outputs":[]},{"metadata":{"_uuid":"8d209788c164e71e83dc6d9daa683da3ad186d78","_cell_guid":"708fdb87-b7b5-403c-bb71-1106e32e65b5","trusted":true},"cell_type":"code","source":"plt.plot(steps_t, acc_t,'bs')\nplt.title(\"Train Acuracy\")\nplt.xlabel(\"Number of Iterarion\")\nplt.ylabel(\"Train Accuracy\")\nplt.show()","execution_count":23,"outputs":[]},{"metadata":{"_uuid":"878fdcf3c89740a38abe1732a927844a4db4201c","_cell_guid":"d3f70040-f673-48ad-a42d-fd667f854936"},"cell_type":"markdown","source":"## Analysis the prediction\n** Test Ac****curacy **"},{"metadata":{"_uuid":"35ad5e5166f9defc49125efe096ebfb6233e375c","_cell_guid":"f85db565-1629-4e5c-b0c4-58fe4f72524b","trusted":true},"cell_type":"code","source":"# Create a boolean array whether each image is correctly classified.\ncorrect = (Y_test_cls == cls_pred)\n\n# Calculate the number of correctly classified images.\n    # When summing a boolean array, False means 0 and True means 1.\ncorrect_sum = correct.sum()\nnum_test = X_test.shape[0]\n# Classification accuracy is the number of correctly classified\n# images divided by the total number of images in the test-set.\nacc = float(correct_sum) / num_test\n# Print the accuracy.\nmsg = \"Accuracy on Test-Set: {0:.1%} ({1} / {2})\"\nprint(msg.format(acc, correct_sum, num_test))","execution_count":24,"outputs":[]},{"metadata":{"_uuid":"4a603f07d828e44403fec2ac709d846aab40f70c","_cell_guid":"a57b257b-407d-4f3b-83bd-86585b241780"},"cell_type":"markdown","source":"** Plot Misclassification**"},{"metadata":{"collapsed":true,"_uuid":"f26435401fb8c91dcd407830e2ddd4855e751c40","_cell_guid":"49c0e29b-00a1-4ff4-b542-8edca5cd1a56","trusted":true},"cell_type":"code","source":"def plot_example_errors(cls_pred, correct):\n    # This function is called from print_test_accuracy() below.\n\n    # cls_pred is an array of the predicted class-number for\n    # all images in the test-set.\n\n    # correct is a boolean array whether the predicted class\n    # is equal to the true class for each image in the test-set.\n\n    # Negate the boolean array.\n    incorrect = (correct == False)\n    \n    # Get the images from the test-set that have been\n    # incorrectly classified.\n    images =new_test_X[incorrect]\n    \n    # Get the predicted classes for those images.\n    cls_pred = cls_pred[incorrect]\n\n    # Get the true classes for those images.\n    cls_true = Y_test_cls[incorrect]\n    \n    # Plot the first 9 images.\n    plot_images(images=images[0:9],\n                cls_true=cls_true[0:9],\n                cls_pred=cls_pred[0:9])","execution_count":25,"outputs":[]},{"metadata":{"_uuid":"8a2a7d8e50f725c8d6c6cefbfebbd60be7bb82a8","_cell_guid":"d13c8ee6-92d7-446c-9c95-bb4dd21e7337","trusted":true},"cell_type":"code","source":"plot_example_errors(cls_pred=cls_pred, correct=correct)","execution_count":26,"outputs":[]},{"metadata":{"collapsed":true,"_uuid":"fb946e792841fd57dc6d4f0d53b7993456b2b142","_cell_guid":"17796dd2-6c34-4d7e-ae23-196859a56050","trusted":true},"cell_type":"code","source":"def plot_confusion_matrix(cls_pred):\n    # This is called from print_test_accuracy() below.\n\n    # cls_pred is an array of the predicted class-number for\n    # all images in the test-set.\n\n    # Get the true classifications for the test-set.\n    cls_true = Y_test_cls\n    \n    # Get the confusion matrix using sklearn.\n    cm = confusion_matrix(y_true=cls_true,\n                          y_pred=cls_pred)\n\n    # Print the confusion matrix as text.\n    print(cm)\n\n    # Plot the confusion matrix as an image.\n    plt.matshow(cm)\n\n    # Make various adjustments to the plot.\n    plt.colorbar()\n    tick_marks = np.arange(num_classes)\n    plt.xticks(tick_marks, range(num_classes))\n    plt.yticks(tick_marks, range(num_classes))\n    plt.xlabel('Predicted')\n    plt.ylabel('True')\n\n    plt.show()","execution_count":27,"outputs":[]},{"metadata":{"_uuid":"9217d52caf28026313b62b7bd97e6d923f5fbd66","_cell_guid":"8cfe1f90-235b-4f85-8335-9122866c2f68","trusted":true},"cell_type":"code","source":"plot_confusion_matrix(cls_pred=cls_pred)","execution_count":28,"outputs":[]},{"metadata":{"_uuid":"e0ffd9726c8f59eb45448bd34bf53cbc82322f67","_cell_guid":"8055241d-eca7-4ce4-8f2c-45f5eafa7e92"},"cell_type":"markdown","source":"It seems that predicting 6 is difficult."},{"metadata":{"_uuid":"cf057105ef6b16a7cf5c226a5bb82c92dcdfae52","_cell_guid":"2dd7705f-c775-421c-890f-7d23e3ac49fb"},"cell_type":"markdown","source":"**Conclusion**\n\n - We could predict the sign language by the ~80% accuracy through apply LeNet CNN. \n - To improve this model you can tube hyperparameters and use other CNN architecture.\n - I provided some references if you are ineterested to go and study more detials  \n - Your comment are warmly welcome.\n - If there is a mistake, please accept my apology in advance."},{"metadata":{"_uuid":"2f115fe26007e5c49ea4a80cef07234070bcef3b","_cell_guid":"c3132694-6647-47c7-a888-bd8a1256663f"},"cell_type":"markdown","source":"** If the notebook is helpful, please upvote! Thanks **"},{"metadata":{"_uuid":"510958074c03fcb73120edc0f555a23f114d618b","_cell_guid":"595a8d38-7951-4563-a0a5-1efab2533ba1"},"cell_type":"markdown","source":"**References**\n\n[1] http://pages.cs.wisc.edu/~bolo/shipyard/neural/local.html#\n\n[2] https://brilliant.org/wiki/backpropagation/\n\n[3] https://machinelearningmastery.com/adam-optimization-algorithm-for-deep-learning/\n\n[4] https://www.coursera.org/learn/deep-neural-network/lecture/w9VCZ/adam-optimization-algorithm\n\n[5] http://ruder.io/optimizing-gradient-descent/\n\n[6] Tensorflow Machine Learning CookBook\n\n[7] Deepleaning.ai Andrew NG (cross-corralation vs. convolution)\n\n[8] http://cs231n.github.io/convolutional-networks/\n\n[9] http://yann.lecun.com/exdb/lenet/\n\n[10] https://medium.com/@siddharthdas_32104/cnns-architectures-lenet-alexnet-vgg-googlenet-resnet-and-more-666091488df5\n\n[11] https://medium.com/@shahariarrabby/lenet-5-alexnet-vgg-16-from-deeplearning-ai-2a4fa5f26344\n\n[12] https://stackoverflow.com/questions/37674306/what-is-the-difference-between-same-and-valid-padding-in-tf-nn-max-pool-of-t\n\n"},{"metadata":{"collapsed":true,"_uuid":"f926f841836de826d2f1e32f67f37beaa1ed1af4","_cell_guid":"8f503dff-fb52-489e-92be-36d2798b76af","trusted":false},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"language_info":{"name":"python","version":"3.6.4","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"}},"nbformat":4,"nbformat_minor":1}